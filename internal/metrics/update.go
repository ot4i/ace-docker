/*
Â© Copyright IBM Corporation 2018

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Package metrics contains code to provide metrics for the queue manager
package metrics

import (
	"crypto/tls"
	"crypto/x509"
	"errors"
	"flag"
	"fmt"
	"io/ioutil"
	"math"
	"net"
	"net/http"
	"net/http/cookiejar"
	"net/url"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/ot4i/ace-docker/common/logger"

	"github.com/gorilla/websocket"
	"github.com/prometheus/client_golang/prometheus"
)

var (
	addr              = flag.String("addr", "localhost:7600", "http service address")
	startChannel      = make(chan bool)
	stopChannel       = make(chan bool, 2)
	stopping          = false
	requestChannel    = make(chan bool)
	responseChannel   = make(chan *MetricsMap)
	statisticsChannel = make(chan StatisticsDataStruct, 10) // Block on writing to channel if we already have 10 queued so we don't retrieve any more
)

type MetricsMap struct {
	sync.Mutex
	internal map[string]*metricData
}

func NewMetricsMap() *MetricsMap {
	return &MetricsMap{
		internal: make(map[string]*metricData),
	}
}

type Metric struct {
	labels prometheus.Labels
	value  float64
}

type metricData struct {
	name        string
	description string
	values      map[string]*Metric
	metricType  MetricType
	metricUnits MetricUnits
	metricLevel MetricLevel
}

/*
Normalise returns a float64 representation of the metric value normalised to a base metric type (seconds, bytes, etc.)
*/
func (md *metricData) Normalise(value int) float64 {
	f := float64(value)

	if f < 0 {
		f = 0
	}

	// Convert microseconds to seconds
	if md.metricUnits == Microseconds {
		f = f / 1000000
	}

	// Convert megabytes to bytes
	if md.metricUnits == MegaBytes {
		f = f * 1024 * 1024
	}

	return f
}

func ReadStatistics(log logger.LoggerInterface) {
	// Check if the admin server is secure so we know whether to connect with wss or ws
	aceAdminServerSecurity := os.Getenv("ACE_ADMIN_SERVER_SECURITY")
	if aceAdminServerSecurity == "" {
		log.Printf("Can't tell if ace admin server security is enabled defaulting to false")
		aceAdminServerSecurity = "false"
	} else {
		log.Printf("ACE_ADMIN_SERVER_SECURITY is %s", aceAdminServerSecurity)
	}

	var firstConnect = true

	for {
		if stopping {
			// Stopping will trigger a read error on the c.ReadJSON call and re-entry into this loop,
			// but we want to exit this function when that happens
			return
		}

		var c *websocket.Conn
		var dialError error

		// Use wss with TLS if using the admin server is secured
		if aceAdminServerSecurity == "true" {
			adminServerCACert := os.Getenv("ACE_ADMIN_SERVER_CA")

			caCertPool := x509.NewCertPool()
			if stat, err := os.Stat(adminServerCACert); err == nil && stat.IsDir() {
				// path is a directory load all certs
				log.Printf("Using CA Certificate folder %s", adminServerCACert)
				filepath.Walk(adminServerCACert, func(cert string, info os.FileInfo, err error) error {
					if strings.HasSuffix(cert, "crt.pem") {
						log.Printf("Adding Certificate %s to CA pool", cert)
						binaryCert, err := ioutil.ReadFile(cert)
						if err != nil {
							log.Errorf("Error reading CA Certificate %s", err)
						}
						ok := caCertPool.AppendCertsFromPEM(binaryCert)
						if !ok {
							log.Errorf("Failed to parse Certificate %s", cert)
						}
					}
					return nil
				})
			} else {
				log.Printf("Using CA Certificate file %s", adminServerCACert)
				caCert, err := ioutil.ReadFile(adminServerCACert)
				if err != nil {
					log.Errorf("Error reading CA Certificate %s", err)
					return
				}
				ok := caCertPool.AppendCertsFromPEM(caCert)
				if !ok {
					log.Errorf("failed to parse root CA Certificate")
				}
			}

			// Read the key/ cert pair to create tls certificate
			adminServerCert := os.Getenv("ACE_ADMIN_SERVER_CERT")
			adminServerKey := os.Getenv("ACE_ADMIN_SERVER_KEY")
			adminServerCerts, err := tls.LoadX509KeyPair(adminServerCert, adminServerKey)
			if err != nil {
				if adminServerCert != "" && adminServerKey != "" {
					log.Errorf("Error reading TLS Certificates: %s", err)
					return
				}
			} else {
				log.Printf("Using provided cert and key for mutual auth")
			}

			aceAdminServerName := os.Getenv("ACE_ADMIN_SERVER_NAME")
			if aceAdminServerName == "" {
				log.Printf("No ace admin server name available")
				return
			} else {
				log.Printf("ACE_ADMIN_SERVER_NAME is %s", aceAdminServerName)
			}

			u := url.URL{Scheme: "wss", Host: *addr, Path: "/"}
			log.Printf("Connecting to %s for statistics gathering", u.String())
			d := websocket.Dialer{
				TLSClientConfig: &tls.Config{
					RootCAs:      caCertPool,
					Certificates: []tls.Certificate{adminServerCerts},
					ServerName:   aceAdminServerName,
				},
			}

			// Retrieve session if the webusers exist
			contentBytes, err := ioutil.ReadFile("/home/aceuser/initial-config/webusers/admin-users.txt")
			if err != nil {
				log.Printf("Cannot find admin-users.txt file, not retrieving session cookie")
			} else {
				log.Printf("Using provided webusers/admin-users.txt for basic auth session cookie")
				userPassword := strings.Fields(string(contentBytes))
				username := userPassword[0]
				password := userPassword[1]

				var conn *tls.Conn
				httpUrl := url.URL{Scheme: "https", Host: *addr, Path: "/"}
				tlsConfig := &tls.Config{
					RootCAs:      caCertPool,
					Certificates: []tls.Certificate{adminServerCerts},
					ServerName:   aceAdminServerName,
				}
				client := &http.Client{
					Transport: &http.Transport{
						DialTLS: func(network, addr string) (net.Conn, error) {
							conn, err = tls.Dial(network, addr, tlsConfig)
							return conn, err
						},
					},
				}
				req, _ := http.NewRequest("GET", httpUrl.String(), nil)
				req.SetBasicAuth(username, password)
				resp, err := client.Do(req)
				if err != nil {
					log.Errorf("Error retrieving session: %s", err)
				}

				jar, _ := cookiejar.New(nil)
				if resp != nil {
					cookies := resp.Cookies()
					jar.SetCookies(&httpUrl, cookies)
				}

				if jar.Cookies(&httpUrl) != nil {
					log.Printf("Connecting to %s using session cookie and SSL", u.String())
					d.Jar = jar
				} else {
					log.Printf("Connecting to %s with SSL", u.String())
				}
			}

			// Create the websocket connection
			c, _, dialError = d.Dial(u.String(), http.Header{"Origin": {u.String()}})
		} else {
			wsUrl := url.URL{Scheme: "ws", Host: *addr, Path: "/"}
			log.Printf("Connecting to %s for statistics", wsUrl.String())

			d := websocket.DefaultDialer

			// Retrieve session if the webusers exist
			contentBytes, err := ioutil.ReadFile("/home/aceuser/initial-config/webusers/admin-users.txt")
			if err != nil {
				log.Printf("Cannot find admin-users.txt file, not retrieving session")
			} else {
				log.Printf("Using provided webusers/admin-users.txt for basic auth session cookie")
				userPassword := strings.Fields(string(contentBytes))
				username := userPassword[0]
				password := userPassword[1]

				httpUrl := url.URL{Scheme: "http", Host: *addr, Path: "/"}
				client := &http.Client{}
				req, _ := http.NewRequest("GET", httpUrl.String(), nil)
				req.SetBasicAuth(username, password)
				resp, err := client.Do(req)
				if err != nil {
					log.Errorf("Error retrieving session: %s", err)
				}

				jar, _ := cookiejar.New(nil)
				if resp != nil {
					cookies := resp.Cookies()
					jar.SetCookies(&httpUrl, cookies)
				}

				if jar.Cookies(&httpUrl) != nil {
					log.Printf("Connecting to %s using session cookie", wsUrl.String())
					d.Jar = jar
				} else {
					log.Printf("Connecting to %s without using session cookie", wsUrl.String())
				}
			}
			// Create the websocket connection
			c, _, dialError = d.Dial(wsUrl.String(), http.Header{"Origin": {wsUrl.String()}})
		}

		if dialError == nil {
			if firstConnect {
				firstConnect = false
				startChannel <- true
			}

			defer c.Close()

			// Loop reading from websocket and put messages on the statistics statisticsChannel
			// End the loop and reconnect if there is an error reading from the websocket
			var readError error
			for readError == nil {
				var m StatisticsDataStruct

				readError = c.ReadJSON(&m)
				if readError == nil {
					statisticsChannel <- m
				}
			}
		} else {
			log.Errorf("Error calling ace admin server webservice endpoint %s", dialError)
			log.Println("If this repeats then check you have assigned enough memory to your Pod and you aren't running out of memory")
			log.Println("Sleeping for 5 seconds before retrying to connect to metrics...")
			time.Sleep(5 * time.Second)
		}
	}
}

// processMetrics processes publications of metric data and handles describe/collect/stop requests
func processMetrics(log logger.LoggerInterface, serverName string) {
	log.Println("Processing metrics...")

	metrics := initialiseMetrics(log)

	go ReadStatistics(log)

	// Handle update/describe/collect/stop requests
	for {
		select {
		case m := <-statisticsChannel:
			newMetrics, parseError := parseMetrics(log, &m)

			if parseError != nil {
				log.Println("Parse Error:", parseError)
			} else {
				updateMetrics(log, metrics, newMetrics)
			}
		case <-requestChannel:
			responseChannel <- metrics
		case <-stopChannel:
			log.Println("Stopping metrics gathering")
			stopping = true
			return
		}
	}
}

// initialiseMetrics sets initial details for all available metrics
func initialiseMetrics(log logger.LoggerInterface) *MetricsMap {

	metrics := NewMetricsMap()
	msgFlowMetricNamesMap, msgFlowNodeMetricNamesMap := generateMetricNamesMap()

	for k, v := range msgFlowMetricNamesMap {
		if v.enabled {
			// Set metric details
			metric := metricData{
				name:        v.name,
				description: v.description,
				metricType:  v.metricType,
				metricUnits: v.metricUnits,
				metricLevel: v.metricLevel,
			}
			metric.values = make(map[string]*Metric)

			// Add metric
			metrics.internal[k] = &metric
		}
	}

	for k, v := range msgFlowNodeMetricNamesMap {
		if v.enabled {
			// Set metric details
			metric := metricData{
				name:        v.name,
				description: v.description,
				metricType:  v.metricType,
				metricUnits: v.metricUnits,
				metricLevel: v.metricLevel,
			}
			metric.values = make(map[string]*Metric)

			// Add metric
			metrics.internal[k] = &metric
		}
	}

	jvmResourceMetricNamesMap := generateResourceMetricNamesMap()

	for k, v := range jvmResourceMetricNamesMap {
		if v.enabled {
			// Set metric details
			metric := metricData{
				name:        v.name,
				description: v.description,
				metricType:  v.metricType,
				metricUnits: v.metricUnits,
				metricLevel: v.metricLevel,
			}
			metric.values = make(map[string]*Metric)

			// Add metric
			metrics.internal[k] = &metric
		}
	}

	return metrics
}

func parseMetrics(log logger.LoggerInterface, m *StatisticsDataStruct) (*MetricsMap, error) {
	if m.Event == ResourceStatisticsData {
		return parseResourceMetrics(log, m)
	} else if m.Event == AccountingAndStatisticsData {
		return parseAccountingMetrics(log, m)
	} else {
		return nil, fmt.Errorf("Unable to parse data with event: %d", m.Event)
	}
}

func parseAccountingMetrics(log logger.LoggerInterface, m *StatisticsDataStruct) (*MetricsMap, error) {
	parsedMetrics := NewMetricsMap()

	msgFlowMetricNamesMap, msgFlowNodeMetricNamesMap := generateMetricNamesMap()

	accountingOrigin := m.Data.WMQIStatisticsAccounting.MessageFlow.AccountingOrigin
	serverName := m.Data.WMQIStatisticsAccounting.MessageFlow.ExecutionGroupName
	applicationName := m.Data.WMQIStatisticsAccounting.MessageFlow.ApplicationName
	msgflowName := m.Data.WMQIStatisticsAccounting.MessageFlow.MessageFlowName

	if msgflowName == "" {
		err := errors.New("parse error - no message flow name in statistics")
		return parsedMetrics, err
	}

	flowValuesMap := map[string]int{
		"MsgFlow/TotalElapsedTime":                                          m.Data.WMQIStatisticsAccounting.MessageFlow.TotalElapsedTime,
		"MsgFlow/MaximumElapsedTime":                                        m.Data.WMQIStatisticsAccounting.MessageFlow.MaximumElapsedTime,
		"MsgFlow/MinimumElapsedTime":                                        m.Data.WMQIStatisticsAccounting.MessageFlow.MinimumElapsedTime,
		"MsgFlow/TotalCpuTime":                                              m.Data.WMQIStatisticsAccounting.MessageFlow.TotalCPUTime,
		"MsgFlow/MaximumCpuTime":                                            m.Data.WMQIStatisticsAccounting.MessageFlow.MaximumCPUTime,
		"MsgFlow/MinimumCpuTime":                                            m.Data.WMQIStatisticsAccounting.MessageFlow.MinimumCPUTime,
		"MsgFlow/TotalSizeOfInputMessages":                                  m.Data.WMQIStatisticsAccounting.MessageFlow.TotalSizeOfInputMessages,
		"MsgFlow/MaximumSizeOfInputMessages":                                m.Data.WMQIStatisticsAccounting.MessageFlow.MaximumSizeOfInputMessages,
		"MsgFlow/MinimumSizeOfInputMessages":                                m.Data.WMQIStatisticsAccounting.MessageFlow.MinimumSizeOfInputMessages,
		"MsgFlow/TotalInputMessages":                                        m.Data.WMQIStatisticsAccounting.MessageFlow.TotalInputMessages,
		"MsgFlow/TotalCPUTimeWaiting":                                       m.Data.WMQIStatisticsAccounting.MessageFlow.CPUTimeWaitingForInputMessage,
		"MsgFlow/TotalElapsedTimeWaiting":                                   m.Data.WMQIStatisticsAccounting.MessageFlow.ElapsedTimeWaitingForInputMessage,
		"MsgFlow/NumberOfThreadsInPool":                                     m.Data.WMQIStatisticsAccounting.MessageFlow.NumberOfThreadsInPool,
		"MsgFlow/TimesMaximumNumberOfThreadsReached":                        m.Data.WMQIStatisticsAccounting.MessageFlow.TimesMaximumNumberOfThreadsReached,
		"MsgFlow/TotalNumberOfMQErrors":                                     m.Data.WMQIStatisticsAccounting.MessageFlow.TotalNumberOfMQErrors,
		"MsgFlow/TotalNumberOfMessagesWithErrors":                           m.Data.WMQIStatisticsAccounting.MessageFlow.TotalNumberOfMessagesWithErrors,
		"MsgFlow/TotalNumberOfErrorsProcessingMessages":                     m.Data.WMQIStatisticsAccounting.MessageFlow.TotalNumberOfErrorsProcessingMessages,
		"MsgFlow/TotalNumberOfTimeOutsWaitingForRepliesToAggregateMessages": m.Data.WMQIStatisticsAccounting.MessageFlow.TotalNumberOfTimeOutsWaitingForRepliesToAggregateMessages,
		"MsgFlow/TotalNumberOfCommits":                                      m.Data.WMQIStatisticsAccounting.MessageFlow.TotalNumberOfCommits,
		"MsgFlow/TotalNumberOfBackouts":                                     m.Data.WMQIStatisticsAccounting.MessageFlow.TotalNumberOfBackouts,
	}

	/*
	   Process flow level accounting and statistics data
	*/
	for k, v := range flowValuesMap {
		metricDesc := msgFlowMetricNamesMap[k]
		if metricDesc.enabled {
			metric := metricData{
				name:        metricDesc.name,
				description: metricDesc.description,
				metricType:  metricDesc.metricType,
				metricUnits: metricDesc.metricUnits,
				metricLevel: metricDesc.metricLevel,
			}
			metric.values = make(map[string]*Metric)
			metric.values[accountingOrigin+"_"+applicationName+"_"+msgflowName] = &Metric{labels: prometheus.Labels{msgflowPrefix: msgflowName, serverLabel: serverName, applicationLabel: applicationName, originLabel: accountingOrigin}, value: metric.Normalise(v)}
			parsedMetrics.internal[k] = &metric
		}
	}

	/*
	   Process node level accounting and statistics data
	*/
	for k, v := range msgFlowNodeMetricNamesMap {

		if v.enabled {
			metric := metricData{
				name:        v.name,
				description: v.description,
				metricType:  v.metricType,
				metricUnits: v.metricUnits,
				metricLevel: v.metricLevel,
			}
			metric.values = make(map[string]*Metric)

			for _, node := range m.Data.WMQIStatisticsAccounting.Nodes {
				nodeValuesMap := map[string]int{
					"MsgFlowNode/TotalElapsedTime":   node.TotalElapsedTime,
					"MsgFlowNode/MaximumElapsedTime": node.MaximumElapsedTime,
					"MsgFlowNode/MinimumElapsedTime": node.MinimumElapsedTime,
					"MsgFlowNode/TotalCpuTime":       node.TotalCPUTime,
					"MsgFlowNode/MaximumCpuTime":     node.MaximumCPUTime,
					"MsgFlowNode/MinimumCpuTime":     node.MinimumCPUTime,
					"MsgFlowNode/TotalInvocations":   node.CountOfInvocations,
					"MsgFlowNode/InputTerminals":     node.NumberOfInputTerminals,
					"MsgFlowNode/OutputTerminals":    node.NumberOfOutputTerminals,
				}
				msgflownodeName := node.Label
				msgflownodeType := node.Type

				metric.values[accountingOrigin+"_"+applicationName+"_"+msgflowName+"_"+msgflownodeName] = &Metric{labels: prometheus.Labels{msgflownodeLabel: msgflownodeName, msgflownodeTypeLabel: msgflownodeType, msgflowLabel: msgflowName, serverLabel: serverName, applicationLabel: applicationName, originLabel: accountingOrigin}, value: metric.Normalise(nodeValuesMap[k])}
			}
			parsedMetrics.internal[k] = &metric
		}
	}

	return parsedMetrics, nil
}

func parseResourceMetrics(log logger.LoggerInterface, m *StatisticsDataStruct) (*MetricsMap, error) {
	parsedResourceMetrics := NewMetricsMap()

	serverName := m.Data.ResourceStatistics.ExecutionGroupName

	for _, v := range m.Data.ResourceStatistics.ResourceType {
		switch v.Name {
		case "JVM":
			jvmData := NewJVMData(v.ResourceIdentifier)

			jvmResourceMetricNamesMap := generateResourceMetricNamesMap()

			jvmValuesMap := map[string]int{
				"JVM/Summary/InitialMemoryInMB":                   jvmData.SummaryInitial,
				"JVM/Summary/UsedMemoryInMB":                      jvmData.SummaryUsed,
				"JVM/Summary/CommittedMemoryInMB":                 jvmData.SummaryCommitted,
				"JVM/Summary/MaxMemoryInMB":                       jvmData.SummaryMax,
				"JVM/Summary/CumulativeGCTimeInSeconds":           jvmData.SummaryGCTime,
				"JVM/Summary/CumulativeNumberOfGCCollections":     jvmData.SummaryGCCount,
				"JVM/Heap/InitialMemoryInMB":                      jvmData.HeapInitial,
				"JVM/Heap/UsedMemoryInMB":                         jvmData.HeapUsed,
				"JVM/Heap/CommittedMemoryInMB":                    jvmData.HeapCommitted,
				"JVM/Heap/MaxMemoryInMB":                          jvmData.HeapMax,
				"JVM/Native/InitialMemoryInMB":                    jvmData.NativeInitial,
				"JVM/Native/UsedMemoryInMB":                       jvmData.NativeUsed,
				"JVM/Native/CommittedMemoryInMB":                  jvmData.NativeCommitted,
				"JVM/Native/MaxMemoryInMB":                        jvmData.NativeMax,
				"JVM/ScavengerGC/CumulativeGCTimeInSeconds":       jvmData.ScavengerGCTime,
				"JVM/ScavengerGC/CumulativeNumberOfGCCollections": jvmData.ScavengerGCCount,
				"JVM/GlobalGC/CumulativeGCTimeInSeconds":          jvmData.GlobalGCTime,
				"JVM/GlobalGC/CumulativeNumberOfGCCollections":    jvmData.GlobalGCCount,
			}

			for metricKey, metricDesc := range jvmResourceMetricNamesMap {
				if metricDesc.enabled {
					metric := metricData{
						name:        metricDesc.name,
						description: metricDesc.description,
						metricType:  metricDesc.metricType,
						metricUnits: metricDesc.metricUnits,
						metricLevel: metricDesc.metricLevel,
					}
					metric.values = make(map[string]*Metric)
					metric.values[metricKey] = &Metric{labels: prometheus.Labels{serverLabel: serverName}, value: metric.Normalise(jvmValuesMap[metricKey])}
					parsedResourceMetrics.internal[metricKey] = &metric
				}
			}
		default:
			//TODO: Support other resource statistic types
		}
	}

	return parsedResourceMetrics, nil
}

// updateMetrics updates values for all available metrics
func updateMetrics(log logger.LoggerInterface, mm1 *MetricsMap, mm2 *MetricsMap) {
	mm1.Lock()
	mm2.Lock()
	defer mm1.Unlock()
	defer mm2.Unlock()

	for k, md2 := range mm2.internal {
		if md1, ok := mm1.internal[k]; ok {
			//Iterate over the labels
			for l, m2 := range md2.values {
				if m1, ok := md1.values[l]; ok {
					switch md1.metricType {
					case Total:
						md1.values[l].value = m1.value + m2.value
					case Maximum:
						md1.values[l].value = math.Max(m1.value, m2.value)
					case Minimum:
						md1.values[l].value = math.Min(m1.value, m2.value)
					case Current:
						md1.values[l].value = m2.value
					default:
						log.Printf("Should not reach here - only a set enumeration of metric types. %d is unknown...", md1.metricType)
					}
				} else {
					md1.values[l] = m2
				}
			}
		} else {
			mm1.internal[k] = mm2.internal[k]
		}
	}
}
